{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78462557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1ed425",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0befd9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d79106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bcb665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f57c5",
   "metadata": {},
   "source": [
    "#### Downsampling ---handle the imbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f232029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit=credit[credit['Class']==0]\n",
    "fraud=credit[credit['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55e06b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21420f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "legit_down=resample(legit, random_state=42, n_samples=len(fraud),replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81e34b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0750b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_credit=pd.concat([fraud,legit_down], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc6b023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273800</th>\n",
       "      <td>165706.0</td>\n",
       "      <td>2.341158</td>\n",
       "      <td>-1.140193</td>\n",
       "      <td>-1.431234</td>\n",
       "      <td>-1.446218</td>\n",
       "      <td>-0.959278</td>\n",
       "      <td>-1.328559</td>\n",
       "      <td>-0.580484</td>\n",
       "      <td>-0.525896</td>\n",
       "      <td>-1.617138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204313</td>\n",
       "      <td>1.250873</td>\n",
       "      <td>-0.096074</td>\n",
       "      <td>0.132532</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.286812</td>\n",
       "      <td>-0.011742</td>\n",
       "      <td>-0.067825</td>\n",
       "      <td>13.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9384</th>\n",
       "      <td>13744.0</td>\n",
       "      <td>-0.300059</td>\n",
       "      <td>0.364418</td>\n",
       "      <td>1.611098</td>\n",
       "      <td>-1.056658</td>\n",
       "      <td>0.652460</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>-0.154589</td>\n",
       "      <td>1.126379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051844</td>\n",
       "      <td>0.166848</td>\n",
       "      <td>-0.294988</td>\n",
       "      <td>-0.818076</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.907665</td>\n",
       "      <td>-0.267201</td>\n",
       "      <td>-0.249516</td>\n",
       "      <td>20.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38205</th>\n",
       "      <td>39293.0</td>\n",
       "      <td>0.813744</td>\n",
       "      <td>-0.617420</td>\n",
       "      <td>1.782595</td>\n",
       "      <td>1.696710</td>\n",
       "      <td>-1.515473</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>-0.893978</td>\n",
       "      <td>0.316722</td>\n",
       "      <td>1.186037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305272</td>\n",
       "      <td>0.919456</td>\n",
       "      <td>-0.114790</td>\n",
       "      <td>0.653273</td>\n",
       "      <td>0.272301</td>\n",
       "      <td>-0.189475</td>\n",
       "      <td>0.091363</td>\n",
       "      <td>0.064843</td>\n",
       "      <td>125.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74642</th>\n",
       "      <td>55681.0</td>\n",
       "      <td>-1.833329</td>\n",
       "      <td>0.046103</td>\n",
       "      <td>2.151713</td>\n",
       "      <td>-0.431903</td>\n",
       "      <td>-0.762017</td>\n",
       "      <td>-0.388451</td>\n",
       "      <td>-0.215207</td>\n",
       "      <td>0.714157</td>\n",
       "      <td>-0.162439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310683</td>\n",
       "      <td>0.559447</td>\n",
       "      <td>-0.071901</td>\n",
       "      <td>0.598248</td>\n",
       "      <td>0.370825</td>\n",
       "      <td>0.617409</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>-0.033303</td>\n",
       "      <td>101.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90141</th>\n",
       "      <td>62878.0</td>\n",
       "      <td>-0.931864</td>\n",
       "      <td>1.459951</td>\n",
       "      <td>0.581482</td>\n",
       "      <td>0.646880</td>\n",
       "      <td>0.438010</td>\n",
       "      <td>-0.279948</td>\n",
       "      <td>0.717567</td>\n",
       "      <td>-0.147485</td>\n",
       "      <td>-0.539104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167936</td>\n",
       "      <td>0.488751</td>\n",
       "      <td>-0.234726</td>\n",
       "      <td>-0.414403</td>\n",
       "      <td>-0.179710</td>\n",
       "      <td>-0.370491</td>\n",
       "      <td>-0.652901</td>\n",
       "      <td>-0.088777</td>\n",
       "      <td>15.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "273800  165706.0  2.341158 -1.140193 -1.431234 -1.446218 -0.959278 -1.328559   \n",
       "9384     13744.0 -0.300059  0.364418  1.611098 -1.056658  0.652460  0.112808   \n",
       "38205    39293.0  0.813744 -0.617420  1.782595  1.696710 -1.515473  0.350754   \n",
       "74642    55681.0 -1.833329  0.046103  2.151713 -0.431903 -0.762017 -0.388451   \n",
       "90141    62878.0 -0.931864  1.459951  0.581482  0.646880  0.438010 -0.279948   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "273800 -0.580484 -0.525896 -1.617138  ...  0.204313  1.250873 -0.096074   \n",
       "9384    0.338364 -0.154589  1.126379  ... -0.051844  0.166848 -0.294988   \n",
       "38205  -0.893978  0.316722  1.186037  ...  0.305272  0.919456 -0.114790   \n",
       "74642  -0.215207  0.714157 -0.162439  ...  0.310683  0.559447 -0.071901   \n",
       "90141   0.717567 -0.147485 -0.539104  ...  0.167936  0.488751 -0.234726   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "273800  0.132532  0.408741  0.286812 -0.011742 -0.067825   13.99      0  \n",
       "9384   -0.818076  0.005634  0.907665 -0.267201 -0.249516   20.33      0  \n",
       "38205   0.653273  0.272301 -0.189475  0.091363  0.064843  125.53      0  \n",
       "74642   0.598248  0.370825  0.617409  0.112006 -0.033303  101.16      0  \n",
       "90141  -0.414403 -0.179710 -0.370491 -0.652901 -0.088777   15.32      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c42c1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "new_credit2=ss.fit_transform(new_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797c8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_credit_scaled=pd.DataFrame(new_credit2,columns=new_credit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2d8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.653269</td>\n",
       "      <td>0.877492</td>\n",
       "      <td>-0.835760</td>\n",
       "      <td>0.329339</td>\n",
       "      <td>-1.170059</td>\n",
       "      <td>0.142252</td>\n",
       "      <td>-0.379208</td>\n",
       "      <td>0.369294</td>\n",
       "      <td>-0.162340</td>\n",
       "      <td>-0.140864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060689</td>\n",
       "      <td>1.061355</td>\n",
       "      <td>-0.070564</td>\n",
       "      <td>0.334623</td>\n",
       "      <td>0.547424</td>\n",
       "      <td>0.570873</td>\n",
       "      <td>-0.081659</td>\n",
       "      <td>-0.223468</td>\n",
       "      <td>-0.366292</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-1.534754</td>\n",
       "      <td>0.396429</td>\n",
       "      <td>-0.421783</td>\n",
       "      <td>0.816880</td>\n",
       "      <td>-1.047275</td>\n",
       "      <td>0.523331</td>\n",
       "      <td>0.422263</td>\n",
       "      <td>0.525397</td>\n",
       "      <td>-0.086609</td>\n",
       "      <td>1.046516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>0.139029</td>\n",
       "      <td>-0.241975</td>\n",
       "      <td>-1.372960</td>\n",
       "      <td>-0.057594</td>\n",
       "      <td>1.874428</td>\n",
       "      <td>-0.330081</td>\n",
       "      <td>-0.623064</td>\n",
       "      <td>-0.339257</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.998760</td>\n",
       "      <td>0.599294</td>\n",
       "      <td>-0.691925</td>\n",
       "      <td>0.844363</td>\n",
       "      <td>-0.179451</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.554573</td>\n",
       "      <td>0.316035</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>1.072335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024768</td>\n",
       "      <td>0.779374</td>\n",
       "      <td>-0.086692</td>\n",
       "      <td>1.270033</td>\n",
       "      <td>0.342643</td>\n",
       "      <td>-0.429150</td>\n",
       "      <td>0.018607</td>\n",
       "      <td>0.068312</td>\n",
       "      <td>0.109334</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.654955</td>\n",
       "      <td>0.117165</td>\n",
       "      <td>-0.509364</td>\n",
       "      <td>0.903516</td>\n",
       "      <td>-0.850361</td>\n",
       "      <td>0.188892</td>\n",
       "      <td>0.143539</td>\n",
       "      <td>0.431351</td>\n",
       "      <td>0.090578</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022843</td>\n",
       "      <td>0.473066</td>\n",
       "      <td>-0.049734</td>\n",
       "      <td>1.171191</td>\n",
       "      <td>0.490517</td>\n",
       "      <td>1.265001</td>\n",
       "      <td>0.038681</td>\n",
       "      <td>-0.147542</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-0.503968</td>\n",
       "      <td>0.281355</td>\n",
       "      <td>-0.120359</td>\n",
       "      <td>0.651882</td>\n",
       "      <td>-0.510343</td>\n",
       "      <td>0.472626</td>\n",
       "      <td>0.203872</td>\n",
       "      <td>0.589819</td>\n",
       "      <td>-0.085160</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073632</td>\n",
       "      <td>0.412915</td>\n",
       "      <td>-0.190045</td>\n",
       "      <td>-0.647839</td>\n",
       "      <td>-0.335774</td>\n",
       "      <td>-0.809216</td>\n",
       "      <td>-0.705158</td>\n",
       "      <td>-0.269547</td>\n",
       "      <td>-0.360621</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "979  1.653269  0.877492 -0.835760  0.329339 -1.170059  0.142252 -0.379208   \n",
       "980 -1.534754  0.396429 -0.421783  0.816880 -1.047275  0.523331  0.422263   \n",
       "981 -0.998760  0.599294 -0.691925  0.844363 -0.179451  0.010745  0.554573   \n",
       "982 -0.654955  0.117165 -0.509364  0.903516 -0.850361  0.188892  0.143539   \n",
       "983 -0.503968  0.281355 -0.120359  0.651882 -0.510343  0.472626  0.203872   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "979  0.369294 -0.162340 -0.140864  ... -0.060689  1.061355 -0.070564   \n",
       "980  0.525397 -0.086609  1.046516  ... -0.151829  0.139029 -0.241975   \n",
       "981  0.316035  0.009518  1.072335  ... -0.024768  0.779374 -0.086692   \n",
       "982  0.431351  0.090578  0.488722  ... -0.022843  0.473066 -0.049734   \n",
       "983  0.589819 -0.085160  0.325704  ... -0.073632  0.412915 -0.190045   \n",
       "\n",
       "          V24       V25       V26       V27       V28    Amount  Class  \n",
       "979  0.334623  0.547424  0.570873 -0.081659 -0.223468 -0.366292   -1.0  \n",
       "980 -1.372960 -0.057594  1.874428 -0.330081 -0.623064 -0.339257   -1.0  \n",
       "981  1.270033  0.342643 -0.429150  0.018607  0.068312  0.109334   -1.0  \n",
       "982  1.171191  0.490517  1.265001  0.038681 -0.147542  0.005416   -1.0  \n",
       "983 -0.647839 -0.335774 -0.809216 -0.705158 -0.269547 -0.360621   -1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_credit_scaled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c49e975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.129097</td>\n",
       "      <td>0.418065</td>\n",
       "      <td>-0.474994</td>\n",
       "      <td>0.568405</td>\n",
       "      <td>-0.717355</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.417675</td>\n",
       "      <td>0.478154</td>\n",
       "      <td>-0.061306</td>\n",
       "      <td>0.558071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200866</td>\n",
       "      <td>-0.12051</td>\n",
       "      <td>-0.009022</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.092291</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>-0.077116</td>\n",
       "      <td>-0.095637</td>\n",
       "      <td>-0.092118</td>\n",
       "      <td>-0.095183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.129097</td>\n",
       "      <td>-0.418065</td>\n",
       "      <td>0.474994</td>\n",
       "      <td>-0.568405</td>\n",
       "      <td>0.717355</td>\n",
       "      <td>-0.376012</td>\n",
       "      <td>-0.417675</td>\n",
       "      <td>-0.478154</td>\n",
       "      <td>0.061306</td>\n",
       "      <td>-0.558071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200866</td>\n",
       "      <td>0.12051</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>-0.022509</td>\n",
       "      <td>-0.092291</td>\n",
       "      <td>-0.003839</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>0.095637</td>\n",
       "      <td>0.092118</td>\n",
       "      <td>0.095183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time        V1        V2        V3        V4        V5        V6  \\\n",
       "Class                                                                         \n",
       "-1.0   0.129097  0.418065 -0.474994  0.568405 -0.717355  0.376012  0.417675   \n",
       " 1.0  -0.129097 -0.418065  0.474994 -0.568405  0.717355 -0.376012 -0.417675   \n",
       "\n",
       "             V7        V8        V9  ...       V20      V21       V22  \\\n",
       "Class                                ...                                \n",
       "-1.0   0.478154 -0.061306  0.558071  ... -0.200866 -0.12051 -0.009022   \n",
       " 1.0  -0.478154  0.061306 -0.558071  ...  0.200866  0.12051  0.009022   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28    Amount  \n",
       "Class                                                                        \n",
       "-1.0   0.022509  0.092291  0.003839 -0.077116 -0.095637 -0.092118 -0.095183  \n",
       " 1.0  -0.022509 -0.092291 -0.003839  0.077116  0.095637  0.092118  0.095183  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_credit_scaled.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a37f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_mean_value(data_train):\n",
    "# for column in data_train.columns:\n",
    "# data_train.fillna(value=data_train[column].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c958a5",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c67749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233512</td>\n",
       "      <td>-0.221414</td>\n",
       "      <td>0.139906</td>\n",
       "      <td>-0.218102</td>\n",
       "      <td>0.273535</td>\n",
       "      <td>0.089773</td>\n",
       "      <td>0.219047</td>\n",
       "      <td>-0.138714</td>\n",
       "      <td>0.147607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060811</td>\n",
       "      <td>0.135912</td>\n",
       "      <td>0.048080</td>\n",
       "      <td>-0.040452</td>\n",
       "      <td>-1.656519e-01</td>\n",
       "      <td>-0.048692</td>\n",
       "      <td>-0.134754</td>\n",
       "      <td>-0.025130</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>-0.129097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.233512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.804595</td>\n",
       "      <td>0.874289</td>\n",
       "      <td>-0.610523</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>0.305197</td>\n",
       "      <td>0.877189</td>\n",
       "      <td>-0.082345</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>-0.039319</td>\n",
       "      <td>-0.054000</td>\n",
       "      <td>-0.076615</td>\n",
       "      <td>-6.255057e-02</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0.198583</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>-0.039367</td>\n",
       "      <td>-0.418065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.221414</td>\n",
       "      <td>-0.804595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861166</td>\n",
       "      <td>0.678791</td>\n",
       "      <td>-0.799292</td>\n",
       "      <td>-0.281851</td>\n",
       "      <td>-0.853825</td>\n",
       "      <td>-0.020316</td>\n",
       "      <td>-0.702367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>0.139198</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>9.492873e-02</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>-0.150375</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.211793</td>\n",
       "      <td>0.474994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.139906</td>\n",
       "      <td>0.874289</td>\n",
       "      <td>-0.861166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.779822</td>\n",
       "      <td>0.850173</td>\n",
       "      <td>0.461559</td>\n",
       "      <td>0.884544</td>\n",
       "      <td>-0.173741</td>\n",
       "      <td>0.769857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.069990</td>\n",
       "      <td>-0.033402</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>-6.891796e-02</td>\n",
       "      <td>-0.032790</td>\n",
       "      <td>0.094202</td>\n",
       "      <td>0.116420</td>\n",
       "      <td>-0.020467</td>\n",
       "      <td>-0.568405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.218102</td>\n",
       "      <td>-0.610523</td>\n",
       "      <td>0.678791</td>\n",
       "      <td>-0.779822</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.585930</td>\n",
       "      <td>-0.456418</td>\n",
       "      <td>-0.715780</td>\n",
       "      <td>0.106552</td>\n",
       "      <td>-0.795567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025921</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>-0.078601</td>\n",
       "      <td>-5.368017e-02</td>\n",
       "      <td>0.152913</td>\n",
       "      <td>-0.004292</td>\n",
       "      <td>-0.058842</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>0.717355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.273535</td>\n",
       "      <td>0.861642</td>\n",
       "      <td>-0.799292</td>\n",
       "      <td>0.850173</td>\n",
       "      <td>-0.585930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295705</td>\n",
       "      <td>0.831434</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>0.657519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>-0.099823</td>\n",
       "      <td>-0.095624</td>\n",
       "      <td>-0.136860</td>\n",
       "      <td>-6.989802e-02</td>\n",
       "      <td>0.047969</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>0.151543</td>\n",
       "      <td>-0.130407</td>\n",
       "      <td>-0.376012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.089773</td>\n",
       "      <td>0.305197</td>\n",
       "      <td>-0.281851</td>\n",
       "      <td>0.461559</td>\n",
       "      <td>-0.456418</td>\n",
       "      <td>0.295705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>-0.567769</td>\n",
       "      <td>0.373651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>-0.012779</td>\n",
       "      <td>0.333409</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-8.496952e-02</td>\n",
       "      <td>-0.041670</td>\n",
       "      <td>-0.157340</td>\n",
       "      <td>-0.018209</td>\n",
       "      <td>0.176880</td>\n",
       "      <td>-0.417675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.219047</td>\n",
       "      <td>0.877189</td>\n",
       "      <td>-0.853825</td>\n",
       "      <td>0.884544</td>\n",
       "      <td>-0.715780</td>\n",
       "      <td>0.831434</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.766359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037154</td>\n",
       "      <td>-0.111161</td>\n",
       "      <td>-0.085828</td>\n",
       "      <td>-0.042620</td>\n",
       "      <td>6.327591e-02</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.127264</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>-0.478154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.138714</td>\n",
       "      <td>-0.082345</td>\n",
       "      <td>-0.020316</td>\n",
       "      <td>-0.173741</td>\n",
       "      <td>0.106552</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>-0.567769</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117375</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>-0.430460</td>\n",
       "      <td>0.090629</td>\n",
       "      <td>2.255038e-01</td>\n",
       "      <td>0.046347</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>-0.007549</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.061306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.147607</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>-0.702367</td>\n",
       "      <td>0.769857</td>\n",
       "      <td>-0.795567</td>\n",
       "      <td>0.657519</td>\n",
       "      <td>0.373651</td>\n",
       "      <td>0.766359</td>\n",
       "      <td>-0.077960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159387</td>\n",
       "      <td>-0.250777</td>\n",
       "      <td>-0.050429</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>2.873555e-02</td>\n",
       "      <td>-0.140126</td>\n",
       "      <td>0.111738</td>\n",
       "      <td>0.122390</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>-0.558071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.210237</td>\n",
       "      <td>0.731406</td>\n",
       "      <td>-0.767601</td>\n",
       "      <td>0.855449</td>\n",
       "      <td>-0.802589</td>\n",
       "      <td>0.757842</td>\n",
       "      <td>0.430759</td>\n",
       "      <td>0.866618</td>\n",
       "      <td>-0.054765</td>\n",
       "      <td>0.855915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088430</td>\n",
       "      <td>-0.209965</td>\n",
       "      <td>-0.051614</td>\n",
       "      <td>-0.002997</td>\n",
       "      <td>4.743974e-02</td>\n",
       "      <td>-0.046190</td>\n",
       "      <td>0.130455</td>\n",
       "      <td>0.115701</td>\n",
       "      <td>-0.007559</td>\n",
       "      <td>-0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.302483</td>\n",
       "      <td>-0.524628</td>\n",
       "      <td>0.607738</td>\n",
       "      <td>-0.711725</td>\n",
       "      <td>0.808163</td>\n",
       "      <td>-0.524679</td>\n",
       "      <td>-0.500921</td>\n",
       "      <td>-0.633904</td>\n",
       "      <td>0.169139</td>\n",
       "      <td>-0.704541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132545</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>-0.028513</td>\n",
       "      <td>-0.120780</td>\n",
       "      <td>-8.826136e-07</td>\n",
       "      <td>0.175660</td>\n",
       "      <td>0.174549</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>0.687511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.256907</td>\n",
       "      <td>0.582658</td>\n",
       "      <td>-0.663614</td>\n",
       "      <td>0.759155</td>\n",
       "      <td>-0.845641</td>\n",
       "      <td>0.616665</td>\n",
       "      <td>0.500904</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>-0.165913</td>\n",
       "      <td>0.763477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070934</td>\n",
       "      <td>-0.104912</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>5.530631e-02</td>\n",
       "      <td>-0.132936</td>\n",
       "      <td>-0.037867</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>-0.685276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.105139</td>\n",
       "      <td>-0.059163</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.067136</td>\n",
       "      <td>0.044688</td>\n",
       "      <td>-0.126987</td>\n",
       "      <td>-0.099462</td>\n",
       "      <td>-0.024930</td>\n",
       "      <td>0.270873</td>\n",
       "      <td>-0.050650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>0.031172</td>\n",
       "      <td>-0.102349</td>\n",
       "      <td>0.029548</td>\n",
       "      <td>-1.940042e-02</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>-0.095935</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>-0.054698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.164612</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>-0.551531</td>\n",
       "      <td>0.653127</td>\n",
       "      <td>-0.799099</td>\n",
       "      <td>0.431203</td>\n",
       "      <td>0.537620</td>\n",
       "      <td>0.541030</td>\n",
       "      <td>-0.185262</td>\n",
       "      <td>0.672168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217574</td>\n",
       "      <td>0.063937</td>\n",
       "      <td>0.021590</td>\n",
       "      <td>0.141461</td>\n",
       "      <td>-5.937543e-02</td>\n",
       "      <td>-0.192141</td>\n",
       "      <td>-0.207018</td>\n",
       "      <td>-0.123208</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>-0.751736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.157858</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>-0.190147</td>\n",
       "      <td>0.169646</td>\n",
       "      <td>-0.146936</td>\n",
       "      <td>0.104054</td>\n",
       "      <td>-0.028064</td>\n",
       "      <td>0.196556</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>0.143016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>-0.048765</td>\n",
       "      <td>0.068224</td>\n",
       "      <td>-3.240237e-02</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.147147</td>\n",
       "      <td>0.088381</td>\n",
       "      <td>0.063597</td>\n",
       "      <td>-0.063861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.231193</td>\n",
       "      <td>0.627373</td>\n",
       "      <td>-0.629198</td>\n",
       "      <td>0.727507</td>\n",
       "      <td>-0.738300</td>\n",
       "      <td>0.690008</td>\n",
       "      <td>0.437835</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>-0.173966</td>\n",
       "      <td>0.723938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145679</td>\n",
       "      <td>-0.101288</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>-0.049444</td>\n",
       "      <td>8.553086e-02</td>\n",
       "      <td>-0.071870</td>\n",
       "      <td>-0.032533</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>-0.031577</td>\n",
       "      <td>-0.595832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.232029</td>\n",
       "      <td>0.666670</td>\n",
       "      <td>-0.637009</td>\n",
       "      <td>0.735928</td>\n",
       "      <td>-0.717522</td>\n",
       "      <td>0.743194</td>\n",
       "      <td>0.422618</td>\n",
       "      <td>0.764894</td>\n",
       "      <td>-0.220758</td>\n",
       "      <td>0.761749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089779</td>\n",
       "      <td>-0.121086</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>-0.078972</td>\n",
       "      <td>5.375690e-02</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.007662</td>\n",
       "      <td>0.049701</td>\n",
       "      <td>-0.035782</td>\n",
       "      <td>-0.556108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.255511</td>\n",
       "      <td>0.676606</td>\n",
       "      <td>-0.622274</td>\n",
       "      <td>0.704057</td>\n",
       "      <td>-0.648888</td>\n",
       "      <td>0.740805</td>\n",
       "      <td>0.369489</td>\n",
       "      <td>0.761831</td>\n",
       "      <td>-0.181103</td>\n",
       "      <td>0.713697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080420</td>\n",
       "      <td>-0.113045</td>\n",
       "      <td>0.026567</td>\n",
       "      <td>-0.117698</td>\n",
       "      <td>6.988244e-02</td>\n",
       "      <td>-0.041288</td>\n",
       "      <td>0.046964</td>\n",
       "      <td>0.085072</td>\n",
       "      <td>-0.006657</td>\n",
       "      <td>-0.470201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>-0.072685</td>\n",
       "      <td>-0.303890</td>\n",
       "      <td>0.225492</td>\n",
       "      <td>-0.329259</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>-0.409462</td>\n",
       "      <td>-0.211576</td>\n",
       "      <td>-0.352794</td>\n",
       "      <td>0.216508</td>\n",
       "      <td>-0.332636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123619</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-1.920939e-01</td>\n",
       "      <td>0.071447</td>\n",
       "      <td>0.055365</td>\n",
       "      <td>-0.030850</td>\n",
       "      <td>0.089436</td>\n",
       "      <td>0.267418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.037284</td>\n",
       "      <td>-0.293816</td>\n",
       "      <td>0.342205</td>\n",
       "      <td>-0.358641</td>\n",
       "      <td>0.309644</td>\n",
       "      <td>-0.305858</td>\n",
       "      <td>-0.152758</td>\n",
       "      <td>-0.402386</td>\n",
       "      <td>-0.026699</td>\n",
       "      <td>-0.404608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514377</td>\n",
       "      <td>0.429553</td>\n",
       "      <td>0.136406</td>\n",
       "      <td>-0.007855</td>\n",
       "      <td>3.639330e-03</td>\n",
       "      <td>0.036259</td>\n",
       "      <td>-0.110247</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>0.051409</td>\n",
       "      <td>0.200866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>-0.060811</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.025921</td>\n",
       "      <td>0.047045</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>0.037154</td>\n",
       "      <td>-0.117375</td>\n",
       "      <td>0.159387</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747260</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>-0.046351</td>\n",
       "      <td>1.318793e-01</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.361572</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.120510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.135912</td>\n",
       "      <td>-0.039319</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.069990</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>-0.099823</td>\n",
       "      <td>-0.012779</td>\n",
       "      <td>-0.111161</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>-0.250777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.747260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.051565</td>\n",
       "      <td>-2.397564e-01</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>-0.374753</td>\n",
       "      <td>-0.253436</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>0.009022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.048080</td>\n",
       "      <td>-0.054000</td>\n",
       "      <td>0.139198</td>\n",
       "      <td>-0.033402</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>-0.095624</td>\n",
       "      <td>0.333409</td>\n",
       "      <td>-0.085828</td>\n",
       "      <td>-0.430460</td>\n",
       "      <td>-0.050429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024636</td>\n",
       "      <td>5.573208e-02</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>-0.184905</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>-0.066985</td>\n",
       "      <td>-0.022509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.040452</td>\n",
       "      <td>-0.076615</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>-0.078601</td>\n",
       "      <td>-0.136860</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.042620</td>\n",
       "      <td>0.090629</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046351</td>\n",
       "      <td>0.051565</td>\n",
       "      <td>-0.024636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.005083e-01</td>\n",
       "      <td>-0.086227</td>\n",
       "      <td>-0.168236</td>\n",
       "      <td>-0.015209</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>-0.092291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.062551</td>\n",
       "      <td>0.094929</td>\n",
       "      <td>-0.068918</td>\n",
       "      <td>-0.053680</td>\n",
       "      <td>-0.069898</td>\n",
       "      <td>-0.084970</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.225504</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131879</td>\n",
       "      <td>-0.239756</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>-0.100508</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.044167</td>\n",
       "      <td>0.191224</td>\n",
       "      <td>0.171454</td>\n",
       "      <td>-0.092634</td>\n",
       "      <td>-0.003839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.048692</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>-0.032790</td>\n",
       "      <td>0.152913</td>\n",
       "      <td>0.047969</td>\n",
       "      <td>-0.041670</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.046347</td>\n",
       "      <td>-0.140126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>-0.086227</td>\n",
       "      <td>4.416663e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161885</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>-0.018472</td>\n",
       "      <td>0.077116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.134754</td>\n",
       "      <td>0.198583</td>\n",
       "      <td>-0.150375</td>\n",
       "      <td>0.094202</td>\n",
       "      <td>-0.004292</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>-0.157340</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.111738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361572</td>\n",
       "      <td>-0.374753</td>\n",
       "      <td>-0.184905</td>\n",
       "      <td>-0.168236</td>\n",
       "      <td>1.912242e-01</td>\n",
       "      <td>0.161885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>0.111012</td>\n",
       "      <td>0.095637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.025130</td>\n",
       "      <td>0.164887</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>0.116420</td>\n",
       "      <td>-0.058842</td>\n",
       "      <td>0.151543</td>\n",
       "      <td>-0.018209</td>\n",
       "      <td>0.127264</td>\n",
       "      <td>-0.007549</td>\n",
       "      <td>0.122390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>-0.253436</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>-0.015209</td>\n",
       "      <td>1.714537e-01</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085613</td>\n",
       "      <td>0.092118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>0.040001</td>\n",
       "      <td>-0.039367</td>\n",
       "      <td>-0.211793</td>\n",
       "      <td>-0.020467</td>\n",
       "      <td>0.011939</td>\n",
       "      <td>-0.130407</td>\n",
       "      <td>0.176880</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>-0.066985</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>-9.263442e-02</td>\n",
       "      <td>-0.018472</td>\n",
       "      <td>0.111012</td>\n",
       "      <td>-0.085613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>-0.129097</td>\n",
       "      <td>-0.418065</td>\n",
       "      <td>0.474994</td>\n",
       "      <td>-0.568405</td>\n",
       "      <td>0.717355</td>\n",
       "      <td>-0.376012</td>\n",
       "      <td>-0.417675</td>\n",
       "      <td>-0.478154</td>\n",
       "      <td>0.061306</td>\n",
       "      <td>-0.558071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>-0.022509</td>\n",
       "      <td>-0.092291</td>\n",
       "      <td>-3.839156e-03</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>0.095637</td>\n",
       "      <td>0.092118</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "Time    1.000000  0.233512 -0.221414  0.139906 -0.218102  0.273535  0.089773   \n",
       "V1      0.233512  1.000000 -0.804595  0.874289 -0.610523  0.861642  0.305197   \n",
       "V2     -0.221414 -0.804595  1.000000 -0.861166  0.678791 -0.799292 -0.281851   \n",
       "V3      0.139906  0.874289 -0.861166  1.000000 -0.779822  0.850173  0.461559   \n",
       "V4     -0.218102 -0.610523  0.678791 -0.779822  1.000000 -0.585930 -0.456418   \n",
       "V5      0.273535  0.861642 -0.799292  0.850173 -0.585930  1.000000  0.295705   \n",
       "V6      0.089773  0.305197 -0.281851  0.461559 -0.456418  0.295705  1.000000   \n",
       "V7      0.219047  0.877189 -0.853825  0.884544 -0.715780  0.831434  0.296104   \n",
       "V8     -0.138714 -0.082345 -0.020316 -0.173741  0.106552 -0.206195 -0.567769   \n",
       "V9      0.147607  0.652857 -0.702367  0.769857 -0.795567  0.657519  0.373651   \n",
       "V10     0.210237  0.731406 -0.767601  0.855449 -0.802589  0.757842  0.430759   \n",
       "V11    -0.302483 -0.524628  0.607738 -0.711725  0.808163 -0.524679 -0.500921   \n",
       "V12     0.256907  0.582658 -0.663614  0.759155 -0.845641  0.616665  0.500904   \n",
       "V13    -0.105139 -0.059163  0.041095 -0.067136  0.044688 -0.126987 -0.099462   \n",
       "V14     0.164612  0.430771 -0.551531  0.653127 -0.799099  0.431203  0.537620   \n",
       "V15    -0.157858  0.132548 -0.190147  0.169646 -0.146936  0.104054 -0.028064   \n",
       "V16     0.231193  0.627373 -0.629198  0.727507 -0.738300  0.690008  0.437835   \n",
       "V17     0.232029  0.666670 -0.637009  0.735928 -0.717522  0.743194  0.422618   \n",
       "V18     0.255511  0.676606 -0.622274  0.704057 -0.648888  0.740805  0.369489   \n",
       "V19    -0.072685 -0.303890  0.225492 -0.329259  0.317460 -0.409462 -0.211576   \n",
       "V20    -0.037284 -0.293816  0.342205 -0.358641  0.309644 -0.305858 -0.152758   \n",
       "V21    -0.060811  0.016772  0.041717  0.032076 -0.025921  0.047045  0.026912   \n",
       "V22     0.135912 -0.039319 -0.008018 -0.069990  0.125219 -0.099823 -0.012779   \n",
       "V23     0.048080 -0.054000  0.139198 -0.033402  0.025987 -0.095624  0.333409   \n",
       "V24    -0.040452 -0.076615  0.009379  0.011276 -0.078601 -0.136860  0.034755   \n",
       "V25    -0.165652 -0.062551  0.094929 -0.068918 -0.053680 -0.069898 -0.084970   \n",
       "V26    -0.048692  0.061006 -0.001354 -0.032790  0.152913  0.047969 -0.041670   \n",
       "V27    -0.134754  0.198583 -0.150375  0.094202 -0.004292  0.167901 -0.157340   \n",
       "V28    -0.025130  0.164887 -0.004355  0.116420 -0.058842  0.151543 -0.018209   \n",
       "Amount  0.040001 -0.039367 -0.211793 -0.020467  0.011939 -0.130407  0.176880   \n",
       "Class  -0.129097 -0.418065  0.474994 -0.568405  0.717355 -0.376012 -0.417675   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "Time    0.219047 -0.138714  0.147607  ... -0.060811  0.135912  0.048080   \n",
       "V1      0.877189 -0.082345  0.652857  ...  0.016772 -0.039319 -0.054000   \n",
       "V2     -0.853825 -0.020316 -0.702367  ...  0.041717 -0.008018  0.139198   \n",
       "V3      0.884544 -0.173741  0.769857  ...  0.032076 -0.069990 -0.033402   \n",
       "V4     -0.715780  0.106552 -0.795567  ... -0.025921  0.125219  0.025987   \n",
       "V5      0.831434 -0.206195  0.657519  ...  0.047045 -0.099823 -0.095624   \n",
       "V6      0.296104 -0.567769  0.373651  ...  0.026912 -0.012779  0.333409   \n",
       "V7      1.000000  0.084690  0.766359  ...  0.037154 -0.111161 -0.085828   \n",
       "V8      0.084690  1.000000 -0.077960  ... -0.117375  0.037700 -0.430460   \n",
       "V9      0.766359 -0.077960  1.000000  ...  0.159387 -0.250777 -0.050429   \n",
       "V10     0.866618 -0.054765  0.855915  ...  0.088430 -0.209965 -0.051614   \n",
       "V11    -0.633904  0.169139 -0.704541  ...  0.132545  0.025587 -0.028513   \n",
       "V12     0.715900 -0.165913  0.763477  ... -0.070934 -0.104912  0.015130   \n",
       "V13    -0.024930  0.270873 -0.050650  ... -0.000625  0.031172 -0.102349   \n",
       "V14     0.541030 -0.185262  0.672168  ... -0.217574  0.063937  0.021590   \n",
       "V15     0.196556  0.139513  0.143016  ...  0.140261 -0.068274 -0.048765   \n",
       "V16     0.743924 -0.173966  0.723938  ... -0.145679 -0.101288  0.000929   \n",
       "V17     0.764894 -0.220758  0.761749  ... -0.089779 -0.121086  0.019496   \n",
       "V18     0.761831 -0.181103  0.713697  ... -0.080420 -0.113045  0.026567   \n",
       "V19    -0.352794  0.216508 -0.332636  ...  0.123619  0.116751 -0.006216   \n",
       "V20    -0.402386 -0.026699 -0.404608  ... -0.514377  0.429553  0.136406   \n",
       "V21     0.037154 -0.117375  0.159387  ...  1.000000 -0.747260  0.128282   \n",
       "V22    -0.111161  0.037700 -0.250777  ... -0.747260  1.000000  0.002021   \n",
       "V23    -0.085828 -0.430460 -0.050429  ...  0.128282  0.002021  1.000000   \n",
       "V24    -0.042620  0.090629  0.009420  ... -0.046351  0.051565 -0.024636   \n",
       "V25     0.063276  0.225504  0.028736  ...  0.131879 -0.239756  0.055732   \n",
       "V26     0.017344  0.046347 -0.140126  ...  0.023976  0.018753  0.035919   \n",
       "V27     0.222347  0.288967  0.111738  ...  0.361572 -0.374753 -0.184905   \n",
       "V28     0.127264 -0.007549  0.122390  ...  0.276189 -0.253436  0.072796   \n",
       "Amount  0.139234  0.021500  0.012546  ...  0.007473  0.022338 -0.066985   \n",
       "Class  -0.478154  0.061306 -0.558071  ...  0.120510  0.009022 -0.022509   \n",
       "\n",
       "             V24           V25       V26       V27       V28    Amount  \\\n",
       "Time   -0.040452 -1.656519e-01 -0.048692 -0.134754 -0.025130  0.040001   \n",
       "V1     -0.076615 -6.255057e-02  0.061006  0.198583  0.164887 -0.039367   \n",
       "V2      0.009379  9.492873e-02 -0.001354 -0.150375 -0.004355 -0.211793   \n",
       "V3      0.011276 -6.891796e-02 -0.032790  0.094202  0.116420 -0.020467   \n",
       "V4     -0.078601 -5.368017e-02  0.152913 -0.004292 -0.058842  0.011939   \n",
       "V5     -0.136860 -6.989802e-02  0.047969  0.167901  0.151543 -0.130407   \n",
       "V6      0.034755 -8.496952e-02 -0.041670 -0.157340 -0.018209  0.176880   \n",
       "V7     -0.042620  6.327591e-02  0.017344  0.222347  0.127264  0.139234   \n",
       "V8      0.090629  2.255038e-01  0.046347  0.288967 -0.007549  0.021500   \n",
       "V9      0.009420  2.873555e-02 -0.140126  0.111738  0.122390  0.012546   \n",
       "V10    -0.002997  4.743974e-02 -0.046190  0.130455  0.115701 -0.007559   \n",
       "V11    -0.120780 -8.826136e-07  0.175660  0.174549  0.031479 -0.003346   \n",
       "V12     0.044559  5.530631e-02 -0.132936 -0.037867  0.002571  0.003960   \n",
       "V13     0.029548 -1.940042e-02  0.074366  0.036672 -0.095935  0.003642   \n",
       "V14     0.141461 -5.937543e-02 -0.192141 -0.207018 -0.123208  0.019051   \n",
       "V15     0.068224 -3.240237e-02  0.036460  0.147147  0.088381  0.063597   \n",
       "V16    -0.049444  8.553086e-02 -0.071870 -0.032533  0.001973 -0.031577   \n",
       "V17    -0.078972  5.375690e-02 -0.055767 -0.007662  0.049701 -0.035782   \n",
       "V18    -0.117698  6.988244e-02 -0.041288  0.046964  0.085072 -0.006657   \n",
       "V19     0.115093 -1.920939e-01  0.071447  0.055365 -0.030850  0.089436   \n",
       "V20    -0.007855  3.639330e-03  0.036259 -0.110247 -0.005167  0.051409   \n",
       "V21    -0.046351  1.318793e-01  0.023976  0.361572  0.276189  0.007473   \n",
       "V22     0.051565 -2.397564e-01  0.018753 -0.374753 -0.253436  0.022338   \n",
       "V23    -0.024636  5.573208e-02  0.035919 -0.184905  0.072796 -0.066985   \n",
       "V24     1.000000 -1.005083e-01 -0.086227 -0.168236 -0.015209  0.056473   \n",
       "V25    -0.100508  1.000000e+00  0.044167  0.191224  0.171454 -0.092634   \n",
       "V26    -0.086227  4.416663e-02  1.000000  0.161885  0.065703 -0.018472   \n",
       "V27    -0.168236  1.912242e-01  0.161885  1.000000  0.252689  0.111012   \n",
       "V28    -0.015209  1.714537e-01  0.065703  0.252689  1.000000 -0.085613   \n",
       "Amount  0.056473 -9.263442e-02 -0.018472  0.111012 -0.085613  1.000000   \n",
       "Class  -0.092291 -3.839156e-03  0.077116  0.095637  0.092118  0.095183   \n",
       "\n",
       "           Class  \n",
       "Time   -0.129097  \n",
       "V1     -0.418065  \n",
       "V2      0.474994  \n",
       "V3     -0.568405  \n",
       "V4      0.717355  \n",
       "V5     -0.376012  \n",
       "V6     -0.417675  \n",
       "V7     -0.478154  \n",
       "V8      0.061306  \n",
       "V9     -0.558071  \n",
       "V10    -0.625459  \n",
       "V11     0.687511  \n",
       "V12    -0.685276  \n",
       "V13    -0.054698  \n",
       "V14    -0.751736  \n",
       "V15    -0.063861  \n",
       "V16    -0.595832  \n",
       "V17    -0.556108  \n",
       "V18    -0.470201  \n",
       "V19     0.267418  \n",
       "V20     0.200866  \n",
       "V21     0.120510  \n",
       "V22     0.009022  \n",
       "V23    -0.022509  \n",
       "V24    -0.092291  \n",
       "V25    -0.003839  \n",
       "V26     0.077116  \n",
       "V27     0.095637  \n",
       "V28     0.092118  \n",
       "Amount  0.095183  \n",
       "Class   1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=new_credit_scaled.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18a8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_featutre=[]\n",
    "for i in corr:\n",
    "    if i=='Class':\n",
    "        for j in corr:\n",
    "            if corr[i][j] >=0.1:\n",
    "                selected_featutre.append(j)\n",
    "            if corr[j][j] <=-0.1:\n",
    "                selected_featutre.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04857044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V2', 'V4', 'V11', 'V19', 'V20', 'V21', 'Class']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_featutre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420a280",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e21bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_sel=new_credit_scaled[selected_featutre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2177929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V11</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015020</td>\n",
       "      <td>0.545855</td>\n",
       "      <td>0.472626</td>\n",
       "      <td>0.057298</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>0.050647</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.390747</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>-0.826659</td>\n",
       "      <td>-0.049164</td>\n",
       "      <td>1.778715</td>\n",
       "      <td>0.102047</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.038011</td>\n",
       "      <td>0.020230</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>-1.338224</td>\n",
       "      <td>-0.530903</td>\n",
       "      <td>-0.238047</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.148309</td>\n",
       "      <td>0.130402</td>\n",
       "      <td>1.081137</td>\n",
       "      <td>-0.029252</td>\n",
       "      <td>-0.295218</td>\n",
       "      <td>0.070693</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.308799</td>\n",
       "      <td>0.777482</td>\n",
       "      <td>0.077198</td>\n",
       "      <td>-2.443721</td>\n",
       "      <td>-0.130441</td>\n",
       "      <td>-0.268255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.835760</td>\n",
       "      <td>-1.170059</td>\n",
       "      <td>-1.004673</td>\n",
       "      <td>-0.440541</td>\n",
       "      <td>-0.502304</td>\n",
       "      <td>-0.060689</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.421783</td>\n",
       "      <td>-1.047275</td>\n",
       "      <td>-0.209500</td>\n",
       "      <td>-0.454584</td>\n",
       "      <td>-0.039518</td>\n",
       "      <td>-0.151829</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-0.691925</td>\n",
       "      <td>-0.179451</td>\n",
       "      <td>-0.783892</td>\n",
       "      <td>-1.098052</td>\n",
       "      <td>-0.095769</td>\n",
       "      <td>-0.024768</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.509364</td>\n",
       "      <td>-0.850361</td>\n",
       "      <td>-0.316865</td>\n",
       "      <td>-0.546563</td>\n",
       "      <td>0.215282</td>\n",
       "      <td>-0.022843</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-0.120359</td>\n",
       "      <td>-0.510343</td>\n",
       "      <td>-1.062578</td>\n",
       "      <td>0.323137</td>\n",
       "      <td>-0.164995</td>\n",
       "      <td>-0.073632</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V2        V4       V11       V19       V20       V21  Class\n",
       "0    0.015020  0.545855  0.472626  0.057298 -0.022957  0.050647    1.0\n",
       "1   -1.390747  0.007119 -0.826659 -0.049164  1.778715  0.102047    1.0\n",
       "2   -0.038011  0.020230  0.052614 -1.338224 -0.530903 -0.238047    1.0\n",
       "3   -0.148309  0.130402  1.081137 -0.029252 -0.295218  0.070693    1.0\n",
       "4    0.308799  0.777482  0.077198 -2.443721 -0.130441 -0.268255    1.0\n",
       "..        ...       ...       ...       ...       ...       ...    ...\n",
       "979 -0.835760 -1.170059 -1.004673 -0.440541 -0.502304 -0.060689   -1.0\n",
       "980 -0.421783 -1.047275 -0.209500 -0.454584 -0.039518 -0.151829   -1.0\n",
       "981 -0.691925 -0.179451 -0.783892 -1.098052 -0.095769 -0.024768   -1.0\n",
       "982 -0.509364 -0.850361 -0.316865 -0.546563  0.215282 -0.022843   -1.0\n",
       "983 -0.120359 -0.510343 -1.062578  0.323137 -0.164995 -0.073632   -1.0\n",
       "\n",
       "[984 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b75e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=credit_sel.drop(['Class'], axis=1)\n",
    "y=credit_sel['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02bb8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f4575",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bab0c0",
   "metadata": {},
   "source": [
    "#### Nave Bye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3ae5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "model=nb.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5322a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.3076923076923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a=accuracy_score(y_pred,y_test)*100\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c9961",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb75d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.92307692307692"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "model2=lg.fit(X_train,y_train)\n",
    "y_lr=model2.predict(X_test)\n",
    "b=accuracy_score(y_lr,y_test)*100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e602cdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.90      0.93       172\n",
      "         1.0       0.90      0.96      0.93       153\n",
      "\n",
      "    accuracy                           0.93       325\n",
      "   macro avg       0.93      0.93      0.93       325\n",
      "weighted avg       0.93      0.93      0.93       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_lr,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b56842",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48099205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.6923076923077"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "mo_dt=dt.fit(X_train,y_train)\n",
    "y_dt=mo_dt.predict(X_test)\n",
    "c=accuracy_score(y_dt,y_test)*100\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb7bc1",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74847afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.38461538461539"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab=AdaBoostClassifier()\n",
    "mo_ab=ab.fit(X_train,y_train)\n",
    "y_ab=mo_ab.predict(X_test)\n",
    "d=accuracy_score(y_ab,y_test)*100\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32aa63b",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25d2157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.6923076923077"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc=GradientBoostingClassifier()\n",
    "mo_gbc=gbc.fit(X_train,y_train)\n",
    "y_gbc=mo_gbc.predict(X_test)\n",
    "e=accuracy_score(y_gbc,y_test)*100\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1a28e",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0777590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_={'Model':['Nave byes','Logistic Regression','Decision Tree','Adaboost','XG boost'],\n",
    "  'Accuracy':[a,b,c,d,e]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f07750c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['Nave byes', 'Logistic Regression', 'Decision Tree', 'Adaboost', 'XG boost'], [88.3076923076923, 92.92307692307692, 87.6923076923077, 91.38461538461539, 91.6923076923077]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a81e14ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nave byes</td>\n",
       "      <td>88.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>92.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>87.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>91.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XG boost</td>\n",
       "      <td>91.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   Accuracy\n",
       "0            Nave byes  88.307692\n",
       "1  Logistic Regression  92.923077\n",
       "2        Decision Tree  87.692308\n",
       "3             Adaboost  91.384615\n",
       "4             XG boost  91.692308"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_visual=pd.DataFrame(dict_)\n",
    "for_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fec2b91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Model Accuracy')\n",
    "sns.barplot(x='Model',y='Accuracy',data=for_visual[['Model','Accuracy']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b165c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "LRparam_grid = {\n",
    "               'n_jobs':[int,None],\n",
    "               'l1_ratio':[float,None],\n",
    "               'verbose':[int,0],\n",
    "               'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'fit_intercept':[bool,True],\n",
    "               'intercept_scaling':[float,1],\n",
    "               'class_weight':['balanced',None],\n",
    "               'C':[100, 10, 1.0, 0.1, 0.01]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a2c4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "485 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "275 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'fit_intercept' parameter of LogisticRegression must be an instance of 'bool', an instance of 'numpy.bool_' or an instance of 'int'. Got <class 'bool'> instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'intercept_scaling' parameter of LogisticRegression must be a float in the range (0.0, inf). Got <class 'float'> instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LogisticRegression must be None or an instance of 'int'. Got <class 'int'> instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of LogisticRegression must be a float in the range [0.0, 1.0] or None. Got <class 'float'> instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'verbose' parameter of LogisticRegression must be an int in the range [0, inf), an instance of 'bool' or an instance of 'numpy.bool_'. Got <class 'int'> instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Subodhita\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.89982651        nan        nan        nan\n",
      "        nan 0.89982651        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.90134166        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;fit_intercept&#x27;: [&lt;class &#x27;bool&#x27;&gt;, True],\n",
       "                                        &#x27;intercept_scaling&#x27;: [&lt;class &#x27;float&#x27;&gt;,\n",
       "                                                              1],\n",
       "                                        &#x27;l1_ratio&#x27;: [&lt;class &#x27;float&#x27;&gt;, None],\n",
       "                                        &#x27;n_jobs&#x27;: [&lt;class &#x27;int&#x27;&gt;, None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                                        &#x27;verbose&#x27;: [&lt;class &#x27;int&#x27;&gt;, 0]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;fit_intercept&#x27;: [&lt;class &#x27;bool&#x27;&gt;, True],\n",
       "                                        &#x27;intercept_scaling&#x27;: [&lt;class &#x27;float&#x27;&gt;,\n",
       "                                                              1],\n",
       "                                        &#x27;l1_ratio&#x27;: [&lt;class &#x27;float&#x27;&gt;, None],\n",
       "                                        &#x27;n_jobs&#x27;: [&lt;class &#x27;int&#x27;&gt;, None],\n",
       "                                        &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                   &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                                        &#x27;verbose&#x27;: [&lt;class &#x27;int&#x27;&gt;, 0]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'fit_intercept': [<class 'bool'>, True],\n",
       "                                        'intercept_scaling': [<class 'float'>,\n",
       "                                                              1],\n",
       "                                        'l1_ratio': [<class 'float'>, None],\n",
       "                                        'n_jobs': [<class 'int'>, None],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag', 'saga'],\n",
       "                                        'verbose': [<class 'int'>, 0]},\n",
       "                   random_state=1, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model=RandomizedSearchCV(estimator = lg,\n",
    "                                   param_distributions =LRparam_grid,\n",
    "                                   n_iter = 100,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 1, \n",
    "                                   random_state = 1,\n",
    "                                  )\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "343068b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='newton-cg')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1211a127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 0,\n",
       " 'solver': 'newton-cg',\n",
       " 'n_jobs': None,\n",
       " 'l1_ratio': None,\n",
       " 'intercept_scaling': 1,\n",
       " 'fit_intercept': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'C': 1.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed0bfeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param={'verbose': [0],\n",
    " 'solver': ['lbfgs'],\n",
    " 'n_jobs': [None],\n",
    " 'l1_ratio': [None],\n",
    " 'intercept_scaling': [1],\n",
    " 'fit_intercept': [True],\n",
    " 'class_weight': ['balanced'],\n",
    " 'C': [1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecc71410",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lg, param, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cca3d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1.0], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;fit_intercept&#x27;: [True], &#x27;intercept_scaling&#x27;: [1],\n",
       "                         &#x27;l1_ratio&#x27;: [None], &#x27;n_jobs&#x27;: [None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;], &#x27;verbose&#x27;: [0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1.0], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;],\n",
       "                         &#x27;fit_intercept&#x27;: [True], &#x27;intercept_scaling&#x27;: [1],\n",
       "                         &#x27;l1_ratio&#x27;: [None], &#x27;n_jobs&#x27;: [None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;], &#x27;verbose&#x27;: [0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1.0], 'class_weight': ['balanced'],\n",
       "                         'fit_intercept': [True], 'intercept_scaling': [1],\n",
       "                         'l1_ratio': [None], 'n_jobs': [None],\n",
       "                         'solver': ['lbfgs'], 'verbose': [0]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_nodel=clf.fit(X_train,y_train)\n",
    "grid_nodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4809397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': 'balanced',\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'n_jobs': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_nodel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed3ffe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_grid_pred=grid_nodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5e86ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.92307692307692"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_grid_pred,y_test)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
